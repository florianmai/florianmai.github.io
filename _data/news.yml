- date: 2026-01-08
  text: 'Our paper "[AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures?](https://arxiv.org/abs/2510.11235)" will be presented at IASEAIâ€™26.'

- date: 2025-12-14
  text: 'Our workshop paper "[Pluralistic AI Alignment: A Cross-Cultural Pilot Survey](https://openreview.net/forum?id=A9oz6qFlQ4)" will be presented at the Second Workshop on Language Models for Underserved Communities (LM4UC).'

- date: 2025-10-27
  text: 'The AI alignment lab at Uni Bonn has started! Learn more on the [course page](https://mai-alignment.github.io/teaching/).'

- date: 2025-10-13
  text: 'New preprint! Leonard Dung and Florian Mai analyze AI alignment strategies from a risk perspective and compare overlaps in failure modes across alignment techniques. [Read the preprint on arXiv.](https://arxiv.org/abs/2510.11235)'

- date: 2025-08-21
  text: 'Our JQL paper has been accepted at EMNLP 2025! [Read the preprint on arXiv.](https://arxiv.org/abs/2505.22232)'

- date: 2025-08-15
  text: 'New preprint! Survey-to-Behavior aligns language models with human values using survey questions. [Check it out on arXiv.](https://arxiv.org/abs/2508.11414)'

- date: 2025-08-08
  text: 'New preprint! We explore in-training defenses against emergent misalignment in language models. [Check it out on arXiv.](https://arxiv.org/abs/2508.06249)'

- date: 2025-03-23
  text: 'Registrations are now open for the [International Conference on Large-Scale AI Risks from 26-28th May 2025](https://www.kuleuven.be/ethics-kuleuven/chair-ai/conference-ai-risks) in Leuven, Belgium. I helped organize this event and I look forward to seeing you there!'

- date: 2025-03-20
  text: 'I am participating in a [panel discussion on trustworthy AI](https://www.deutsches-museum.de/bonn/programm/veranstaltung/vertrauenswuerdige-ki) at the Deutsches Museum Bonn.'

- date: 2025-03-06
  text: 'Our paper "[Superalignment with Dynamic Human Values](https://arxiv.org/abs/2503.13621)" was accepted at the BiAlign Workshop at ICLR 2025!'

- date: 2025-01-01
  text: 'I started as a Junior Research Group Leader at University of Bonn as a part of the CAISA lab headed by Prof. Lucie Flek. My research will focus on AI safety topics like value alignment, and on reasoning and planning approaches for LLMs.'

- date: 2024-10-01
  text: 'I am starting a short-term scholarship at the CAISA lab at the University of Bonn, funded through the DAAD AInet program! Our project will focus on drafting a new approach to the [scalable oversight problem].(https://aisafety.info/questions/8EL8/What-is-scalable-oversight)'
