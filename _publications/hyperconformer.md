---
title: "HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition"
collection: publications
excerpt: 'We show that the attention mechanism in the popular Conformer architecture can be replaced with a more efficient alternative at no performance loss.'
date: 2023-08-01
venue: 'InterSpeech'
selected: false
pubtype: 'peerreviewed'
paperurl: 'https://arxiv.org/abs/2305.18281'
citation: 'Florian Mai, Juan Zuluaga-Gomez, Titouan Parcollet and Petr Motlicek (2023). &quot;HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition.&quot; <i>InterSpeech 2023</i>.'
---
We show that the attention mechanism in the popular Conformer architecture can be replaced with a more efficient alternative at no performance loss.

[Download paper here](https://arxiv.org/abs/2305.18281)
